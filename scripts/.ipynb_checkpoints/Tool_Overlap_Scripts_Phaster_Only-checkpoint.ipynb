{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Tool Overlap and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "### Import Data\n",
    "IVS = pd.read_csv(\"../data/Prophage_Tool_Predictions/Isolates_Virsorter.csv\")\n",
    "IP = pd.read_csv(\"../data/Prophage_Tool_Predictions/Isolates_Phaster.csv\")\n",
    "CVS = pd.read_csv(\"../data/Prophage_Tool_Predictions/Complete_Genomes_VirSorter.csv\")\n",
    "CP = pd.read_csv(\"../data/Prophage_Tool_Predictions/Complete_Genomes_Phaster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_intersect(r1_s, r1_e, r2_s, r2_e):\n",
    "    return len(range(max(r1_s,r2_s), min(r1_e,r2_e))) or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of prophages predicted across both tools in all confidence levels: 2072\n"
     ]
    }
   ],
   "source": [
    "### Unique Identifiers\n",
    "\n",
    "#### IVS\n",
    "IVS[\"Contig\"] = IVS[\"Contig\"].astype(str)\n",
    "IVS[\"Start\"] = IVS[\"Start\"].astype(str)\n",
    "IVS[\"End\"] = IVS['End'].astype(str)\n",
    "IVS[\"Unique\"] = IVS[\"Identifier\"] + IVS[\"Contig\"] + IVS[\"Start\"] + IVS[\"End\"]\n",
    "IVS[\"Contig\"] = IVS[\"Contig\"].astype(int)\n",
    "IVS[\"Start\"] = IVS[\"Start\"].astype(int)\n",
    "IVS[\"End\"] = IVS['End'].astype(int)\n",
    "\n",
    "### IP \n",
    "IP[\"Contig\"] = IP[\"Contig\"].astype(str)\n",
    "IP[\"Start\"] = IP[\"Start\"].astype(str)\n",
    "IP[\"End\"] = IP['End'].astype(str)\n",
    "IP[\"Unique\"] = IP[\"Identifier\"] + IP[\"Contig\"] + IP[\"Start\"] + IP[\"End\"]\n",
    "IP[\"Contig\"] = IP[\"Contig\"].astype(int)\n",
    "IP[\"Start\"] = IP[\"Start\"].astype(int)\n",
    "IP[\"End\"] = IP['End'].astype(int)\n",
    "\n",
    "### CP\n",
    "CP[\"Start\"] = CP[\"Start\"].astype(str)\n",
    "CP[\"End\"] = CP['End'].astype(str)\n",
    "CP[\"Unique\"] = CP[\"ID\"] + CP[\"Start\"] + CP[\"End\"]\n",
    "CP[\"Start\"] = CP[\"Start\"].astype(int)\n",
    "CP[\"End\"] = CP['End'].astype(int)\n",
    "\n",
    "#### IVS\n",
    "CVS[\"Start\"] = CVS[\"Start\"].astype(str)\n",
    "CVS[\"End\"] = CVS['End'].astype(str)\n",
    "CVS[\"Unique\"] = CVS[\"ID\"] + CVS[\"Start\"] + CVS[\"End\"]\n",
    "CVS[\"Start\"] = CVS[\"Start\"].astype(int)\n",
    "CVS[\"End\"] = CVS['End'].astype(int)\n",
    "\n",
    "\n",
    "## Replace Contigs Scoring to Prophage\n",
    "IVS[\"Category\"] = IVS[\"Category\"].astype(str)\n",
    "IVS['Category'] = IVS['Category'].str.replace('1','7')\n",
    "IVS['Category'] = IVS['Category'].str.replace('2','8')\n",
    "IVS['Category'] = IVS['Category'].str.replace('3','9')\n",
    "\n",
    "## Replace Phaster Naming Convention w/ groups \n",
    "CP['Category'] = CP['Category'].str.replace('intact','4')\n",
    "CP['Category'] = CP['Category'].str.replace('questionable','5')\n",
    "CP['Category'] = CP['Category'].str.replace('incomplete','6')\n",
    "CP[\"Category\"] = pd.to_numeric(CP[\"Category\"])\n",
    "CVS[\"Category\"] = pd.to_numeric(CVS[\"Category\"])\n",
    "\n",
    "## Replace Phaster Naming Convention w/ groups \n",
    "IP['Category'] = IP['Category'].str.replace('intact','4')\n",
    "IP['Category'] = IP['Category'].str.replace('questionable','5')\n",
    "IP['Category'] = IP['Category'].str.replace('incomplete','6')\n",
    "IP[\"Category\"] = pd.to_numeric(IP[\"Category\"])\n",
    "IVS[\"Category\"] = pd.to_numeric(IVS[\"Category\"])\n",
    "\n",
    "x = len(IVS)+len(IP)+len(CP)+len(CVS)\n",
    "print(\"Total number of prophages predicted across both tools in all confidence levels: \" + str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genomes with predicted prophages from Phaster any quality:53\n",
      "Genomes with predicted prophages from VirSorter any quality:47\n"
     ]
    }
   ],
   "source": [
    "print('Genomes with predicted prophages from Phaster any quality:' + str(len(set(CP[\"ID\"]))))\n",
    "print('Genomes with predicted prophages from VirSorter any quality:' + str(len(set(CVS[\"GCF\"]))))\n",
    "in_both_complete = set(CP[\"ID\"])&set(CVS[\"GCF\"])\n",
    "missing = set(CP[\"ID\"])-set(CVS[\"GCF\"])\n",
    "\n",
    "CPB = CP[CP[\"ID\"].isin(in_both_complete)]\n",
    "CVSB = CVS[CVS[\"GCF\"].isin(in_both_complete)]\n",
    "\n",
    "## Split dataframe into list of smaller dataframes by GCF IDs\n",
    "gb = CVSB.groupby('GCF')\n",
    "y = [gb.get_group(x) for x in gb.groups]\n",
    "\n",
    "gb = CPB.groupby('ID')\n",
    "z = [gb.get_group(x) for x in gb.groups]\n",
    "\n",
    "my_set = set()\n",
    "my_other_set = set()\n",
    "\n",
    "count = 0 \n",
    "\n",
    "for item in range(len(z)):\n",
    "    name_z = list(z[item][\"ID\"])[0]\n",
    "    name_y = list(y[item][\"GCF\"])[0]\n",
    "    if name_z != name_y:\n",
    "        print(\"IDs do not match: \")\n",
    "    df_y=y[item]\n",
    "    df_z=z[item]\n",
    "    \n",
    "    #def overlap remaining\n",
    "\n",
    "    for item in range(len(df_y)):\n",
    "        ### Get Start and End Position of Y\n",
    "        unique_y = df_y.iloc[item].Unique\n",
    "        start_y = df_y.iloc[item].Start\n",
    "        end_y = df_y.iloc[item].End\n",
    "        \n",
    "        for j in range(len(df_z)):\n",
    "            unique_z = df_z.iloc[j].Unique\n",
    "            start_z = df_z.iloc[j].Start\n",
    "            end_z = df_z.iloc[j].End\n",
    "            \n",
    "            out = range_intersect(start_y, end_y, start_z, end_z)\n",
    "            \n",
    "            if out != None:\n",
    "                count+=1\n",
    "                if df_y.iloc[item].Category >= df_z.iloc[j].Category:\n",
    "                    my_set.add(unique_z)\n",
    "                    my_other_set.add(unique_y)\n",
    "                                    ## If categories are equal, take longer predicted phage\n",
    "                elif df_y.iloc[item].Category == df_z.iloc[j].Category:\n",
    "                    if df_y.iloc[item].Length > df_z.iloc[j].Length:\n",
    "                        my_set.add(unique_z)\n",
    "                        my_other_set.add(unique_y)\n",
    "                    else:\n",
    "                        my_set.add(unique_z)\n",
    "                        my_other_set.add(unique_y)\n",
    "                else:\n",
    "                    my_set.add(unique_z)\n",
    "                    my_other_set.add(unique_y)\n",
    "combined_set = set(list(my_set)+list(my_other_set))\n",
    "\n",
    "\n",
    "overlapped_retained_CVSB = CVSB[CVSB[\"Unique\"].isin(my_set)]\n",
    "overlapped_discarded_CVSB = CVSB[CVSB[\"Unique\"].isin(my_other_set)]\n",
    "overlapped_combined_CVSB = CVSB[CVSB[\"Unique\"].isin(combined_set)]\n",
    "nonoverlap_CVSB = CVSB[~CVSB[\"Unique\"].isin(combined_set)]\n",
    "## -------------------------\n",
    "overlapped_retained_CPB = CPB[CPB[\"Unique\"].isin(my_set)]\n",
    "overlapped_discarded_CPB = CPB[CPB[\"Unique\"].isin(my_other_set)]\n",
    "overlapped_combined_CPB = CPB[CPB[\"Unique\"].isin(combined_set)]\n",
    "nonoverlap_CPB = CPB[~CPB[\"Unique\"].isin(combined_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stronglab2/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "df_overlapped = overlapped_retained_CVSB[[\"ID\", \"Category\", \"Start\", \"End\", \"Length\",\"Species.1\"]]\n",
    "df_overlapped.columns = [\"ID\", \"Category\", \"Start\", \"End\", \"Length\", \"Species\"]\n",
    "df_overlapped['AttP'] = \"Not Applicable\"\n",
    "df_y_o2 = overlapped_retained_CPB[[\"ID\", \"Category\", \"Start\", \"End\", \"Length\", \"Species\", \"AttP Site\"]]\n",
    "df_y_o2.columns = [\"ID\", \"Category\", \"Start\", \"End\", \"Length\", \"Species\", \"AttP\"]\n",
    "df_overlapped = df_overlapped.append(df_y_o2)\n",
    "\n",
    "\n",
    "## Subset and combine tools\n",
    "df_total = nonoverlap_CVSB[[\"ID\", \"Category\", \"Start\", \"End\", \"Length\",\"Species.1\"]]\n",
    "df_total.columns = [\"ID\", \"Category\", \"Start\", \"End\", \"Length\", \"Species\"]\n",
    "df_total['AttP'] = \"Not Applicable\"\n",
    "df_y_o2 = nonoverlap_CPB[[\"ID\", \"Category\", \"Start\", \"End\", \"Length\", \"Species\", \"AttP Site\"]]\n",
    "df_y_o2.columns = [\"ID\", \"Category\", \"Start\", \"End\", \"Length\", \"Species\", \"AttP\"]\n",
    "df_total = df_total.append(df_y_o2)\n",
    "\n",
    "## Combined overlap and non overlapping predictions\n",
    "df_total = df_total.append(df_overlapped)\n",
    "\n",
    "test = CVS[[\"ID\", \"GCF\"]]\n",
    "test = test.set_index(\"ID\")\n",
    "test = test.drop_duplicates()\n",
    "y = test.to_dict()\n",
    "y = y.get(\"GCF\")\n",
    "df_overlapped[\"ID\"] = df_overlapped[\"ID\"].replace(y)\n",
    "df_total[\"ID\"] = df_total[\"ID\"].replace(y)\n",
    "\n",
    "\n",
    "df_overlapped[\"Start\"] = df_overlapped[\"Start\"].astype(str)\n",
    "df_overlapped[\"End\"] = df_overlapped['End'].astype(str)\n",
    "df_overlapped[\"Unique\"] = df_overlapped[\"ID\"] + \"-\"+ df_overlapped[\"Start\"] + \"-\"+ df_overlapped[\"End\"]\n",
    "df_overlapped[\"Start\"] = df_overlapped[\"Start\"].astype(int)\n",
    "df_overlapped[\"End\"] = df_overlapped['End'].astype(int)\n",
    "\n",
    "df_overlapped = df_overlapped.reset_index()\n",
    "df_overlapped = df_overlapped.drop(\"index\", axis=1)\n",
    "\n",
    "my_set = set()\n",
    "\n",
    "for item in range(len(df_overlapped)):\n",
    "    ## Split Row from Dataframe\n",
    "    row_of_interest = df_overlapped.iloc[item]\n",
    "    df_without_row = df_overlapped.drop(item)\n",
    "    ## Perform Comparison of Row Characterisitics \n",
    "    ## Identifier is a column that I want to compare\n",
    "    for j in range(len(df_without_row)):\n",
    "        if df_without_row.iloc[j][\"ID\"] == row_of_interest[\"ID\"]:\n",
    "            \n",
    "            ## \n",
    "            ds = df_without_row.iloc[j][\"Start\"]\n",
    "            de = df_without_row.iloc[j][\"End\"]\n",
    "            dc = df_without_row.iloc[j][\"Category\"]\n",
    "            dl = df_without_row.iloc[j][\"Length\"]\n",
    "            du = df_without_row.iloc[j][\"Unique\"]\n",
    "            \n",
    "            ## \n",
    "            rs = row_of_interest[\"Start\"]\n",
    "            re = row_of_interest[\"End\"]\n",
    "            rc = row_of_interest[\"Category\"]\n",
    "            rl = row_of_interest[\"Length\"]\n",
    "            ru = row_of_interest[\"Unique\"]\n",
    "            \n",
    "            out = range_intersect(rs, re, ds, de)\n",
    "            \n",
    "            if out != None:\n",
    "                if rc == dc:\n",
    "                    if rl <= dl:\n",
    "                        my_set.add(ru)\n",
    "                    else:\n",
    "                        my_set.add(du)\n",
    "                elif rc < dc:\n",
    "                    my_set.add(du)\n",
    "                    \n",
    "                else:\n",
    "                    my_set.add(ru)\n",
    "df_overlapped = df_overlapped[~df_overlapped[\"Unique\"].isin(list(my_set))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of overlapping prophages retained from Phaster (with attachment site predictions): 86.84%\n",
      "Percentage of overlapping prophages with AttP sites: 57.89%\n",
      "Percentage of overlapping prophages with AttP sites only from Phaster predictions: 66.67%\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of overlapping prophages retained from Phaster (with attachment site predictions): \" + str(round(((33.0/38)*100),2)) + \"%\")\n",
    "print(\"Percentage of overlapping prophages with AttP sites: \" + str(round(((22.0/38)*100),2)) + \"%\")\n",
    "print(\"Percentage of overlapping prophages with AttP sites only from Phaster predictions: \" + str(round(((22.0/33)*100),2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Files \n",
    "df_overlapped.to_csv(\"../data/Tables/Overlapped_Prophages_Complete_Phaster.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genomes with predicted prophages from Phaster any quality:179\n",
      "Genomes with predicted prophages from VirSorter any quality:180\n"
     ]
    }
   ],
   "source": [
    "print('Genomes with predicted prophages from Phaster any quality:' + str(len(set(IP[\"Identifier\"]))))\n",
    "print('Genomes with predicted prophages from VirSorter any quality:' + str(len(set(IVS[\"Identifier\"]))))\n",
    "in_both_complete = set(IP[\"Identifier\"])&set(IVS[\"Identifier\"])\n",
    "missing = set(IP[\"Identifier\"])-set(IVS[\"Identifier\"])\n",
    "\n",
    "IPB = IP[IP[\"Identifier\"].isin(in_both_complete)]\n",
    "IVSB = IVS[IVS[\"Identifier\"].isin(in_both_complete)]\n",
    "\n",
    "## Split dataframe into list of smaller dataframes by GCF IDs\n",
    "gb = IVSB.groupby('Identifier')\n",
    "y = [gb.get_group(x) for x in gb.groups]\n",
    "\n",
    "gb = IPB.groupby('Identifier')\n",
    "z = [gb.get_group(x) for x in gb.groups]\n",
    "\n",
    "my_set = set()\n",
    "my_other_set = set()\n",
    "\n",
    "count = 0 \n",
    "\n",
    "for item in range(len(z)):\n",
    "    name_z = list(z[item][\"Identifier\"])[0]\n",
    "    name_y = list(y[item][\"Identifier\"])[0]\n",
    "    if name_z != name_y:\n",
    "        print(\"IDs do not match: \")\n",
    "    df_y=y[item]\n",
    "    df_z=z[item]\n",
    "    \n",
    "\n",
    "\n",
    "    for item in range(len(df_y)):\n",
    "        unique_y = df_y.iloc[item].Unique\n",
    "        start_y = df_y.iloc[item].Start\n",
    "        end_y = df_y.iloc[item].End\n",
    "        contig_y = df_y.iloc[item].Contig\n",
    "        \n",
    "        for j in range(len(df_z)):\n",
    "            unique_z = df_z.iloc[j].Unique\n",
    "            start_z = df_z.iloc[j].Start\n",
    "            end_z = df_z.iloc[j].End\n",
    "            contig_z = df_z.iloc[j].Contig\n",
    "            \n",
    "            if contig_z == contig_y:\n",
    "                \n",
    "                out = range_intersect(start_y, end_y, start_z, end_z)\n",
    "            \n",
    "                if out != None:\n",
    "                    count+=1\n",
    "                    if df_y.iloc[item].Category >= df_z.iloc[j].Category:\n",
    "                        my_set.add(unique_z)\n",
    "                        my_other_set.add(unique_y)\n",
    "                                    ## If categories are equal, take longer predicted phage\n",
    "                    elif df_y.iloc[item].Category == df_z.iloc[j].Category:\n",
    "                        if df_y.iloc[item].Length > df_z.iloc[j].Length:\n",
    "                            my_set.add(unique_z)\n",
    "                            my_other_set.add(unique_y)\n",
    "                        else:\n",
    "                            my_set.add(unique_z)\n",
    "                            my_other_set.add(unique_y)\n",
    "                    else:\n",
    "                        my_set.add(unique_z)\n",
    "                        my_other_set.add(unique_y)\n",
    "combined_set = set(list(my_set)+list(my_other_set))\n",
    "\n",
    "\n",
    "overlapped_retained_IVSB = IVSB[IVSB[\"Unique\"].isin(my_set)]\n",
    "overlapped_discarded_IVSB = IVSB[IVSB[\"Unique\"].isin(my_other_set)]\n",
    "overlapped_combined_IVSB = IVSB[IVSB[\"Unique\"].isin(combined_set)]\n",
    "nonoverlap_IVSB = IVSB[~IVSB[\"Unique\"].isin(combined_set)]\n",
    "## -------------------------\n",
    "overlapped_retained_IPB = IPB[IPB[\"Unique\"].isin(my_set)]\n",
    "overlapped_discarded_IPB = IPB[IPB[\"Unique\"].isin(my_other_set)]\n",
    "overlapped_combined_IPB = IPB[IPB[\"Unique\"].isin(combined_set)]\n",
    "nonoverlap_IPB = IPB[~IPB[\"Unique\"].isin(combined_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Overlapping Identifiers\n",
    "nonoverlap_IP = IP[~IP[\"Unique\"].isin(combined_set)]\n",
    "nonoverlap_IVS = IVS[~IVS[\"Unique\"].isin(combined_set)]\n",
    "\n",
    "## \n",
    "overlapped_combined_IVSB\n",
    "df_overlapped = overlapped_retained_IVSB[[\"Identifier\", \"Category\", \"Contig\", \"Start\", \"End\", \"Length\",\"Species\"]]\n",
    "df_overlapped.columns = [\"Identifier\", \"Category\", \"Contig\",\"Start\", \"End\", \"Length\", \"Species\"]\n",
    "df_overlapped['AttP'] = \"Not Applicable\"\n",
    "df_y_o2 = overlapped_retained_IPB[[\"Identifier\", \"Category\", \"Contig\",\"Start\", \"End\", \"Length\", \"Species\", \"AttP Site\"]]\n",
    "df_y_o2.columns = [\"Identifier\", \"Category\", \"Contig\", \"Start\", \"End\", \"Length\", \"Species\", \"AttP\"]\n",
    "df_overlapped = df_overlapped.append(df_y_o2)\n",
    "\n",
    "## Subset and combine tools\n",
    "df_total = nonoverlap_IVS[[\"Identifier\", \"Category\", \"Contig\",\"Start\", \"End\", \"Length\",\"Species\"]]\n",
    "df_total.columns = [\"Identifier\", \"Category\", \"Contig\",\"Start\", \"End\", \"Length\", \"Species\"]\n",
    "df_total['AttP'] = \"Not Applicable\"\n",
    "df_y_o2 = nonoverlap_IP[[\"Identifier\", \"Category\", \"Contig\",\"Start\", \"End\", \"Length\", \"Species\", \"AttP Site\"]]\n",
    "df_y_o2.columns = [\"Identifier\", \"Category\", \"Contig\",\"Start\", \"End\", \"Length\", \"Species\", \"AttP\"]\n",
    "df_total = df_total.append(df_y_o2)\n",
    "\n",
    "## Combined overlap and non overlapping predictions\n",
    "df_total = df_total.append(df_overlapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlapped[\"Contig\"] = df_overlapped[\"Contig\"].astype(str)\n",
    "df_overlapped[\"Start\"] = df_overlapped[\"Start\"].astype(str)\n",
    "df_overlapped[\"End\"] = df_overlapped['End'].astype(str)\n",
    "df_overlapped[\"Unique\"] = df_overlapped['Identifier'] + \"-\" + df_overlapped['Contig'] + \"-\" + df_overlapped['Start'] + \"-\" + df_overlapped[\"End\"]\n",
    "df_overlapped[\"Contig\"] = df_overlapped[\"Contig\"].astype(int)\n",
    "df_overlapped[\"Start\"] = df_overlapped[\"Start\"].astype(int)\n",
    "df_overlapped[\"End\"] = df_overlapped['End'].astype(int)\n",
    "\n",
    "df_overlapped = df_overlapped.reset_index()\n",
    "df_overlapped = df_overlapped.drop(\"index\", axis=1)\n",
    "\n",
    "my_set = set()\n",
    "\n",
    "for item in range(len(df_overlapped)):\n",
    "    ## Split Row from Dataframe\n",
    "    row_of_interest = df_overlapped.iloc[item]\n",
    "    df_without_row = df_overlapped.drop(item)\n",
    "    ## Perform Comparison of Row Characterisitics \n",
    "    ## Identifier is a column that I want to compare\n",
    "    for j in range(len(df_without_row)):\n",
    "        if df_without_row.iloc[j][\"Identifier\"] == row_of_interest[\"Identifier\"]:\n",
    "            if df_without_row.iloc[j][\"Contig\"] == row_of_interest[\"Contig\"]:\n",
    "            \n",
    "            ## \n",
    "                ds = df_without_row.iloc[j][\"Start\"]\n",
    "                de = df_without_row.iloc[j][\"End\"]\n",
    "                dc = df_without_row.iloc[j][\"Category\"]\n",
    "                dl = df_without_row.iloc[j][\"Length\"]\n",
    "                du = df_without_row.iloc[j][\"Unique\"]\n",
    "            \n",
    "            ## \n",
    "                rs = row_of_interest[\"Start\"]\n",
    "                re = row_of_interest[\"End\"]\n",
    "                rc = row_of_interest[\"Category\"]\n",
    "                rl = row_of_interest[\"Length\"]\n",
    "                ru = row_of_interest[\"Unique\"]\n",
    "            \n",
    "                out = range_intersect(rs, re, ds, de)\n",
    "            \n",
    "                if out != None:\n",
    "                    if rc == dc:\n",
    "                        if rl <= dl:\n",
    "                            my_set.add(ru)\n",
    "                        else:\n",
    "                            my_set.add(du)\n",
    "                    elif rc < dc:\n",
    "                        my_set.add(du)\n",
    "                    \n",
    "                    else:\n",
    "                        my_set.add(ru)\n",
    "df_overlapped = df_overlapped[~df_overlapped[\"Unique\"].isin(list(my_set))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of overlapping prophages retained from Phaster (with attachment site predictions): 61.33%\n",
      "Percentage of overlapping prophages with AttP sites: 31.33%\n",
      "Percentage of overlapping prophages with AttP sites only from Phaster predictions: 51.09%\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of overlapping prophages retained from Phaster (with attachment site predictions): \" + str(round(((92.0/150)*100),2)) + \"%\")\n",
    "print(\"Percentage of overlapping prophages with AttP sites: \" + str(round(((47.0/150)*100),2)) + \"%\")\n",
    "print(\"Percentage of overlapping prophages with AttP sites only from Phaster predictions: \" + str(round(((47.0/92)*100),2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Files \n",
    "df_overlapped.to_csv(\"../data/Tables/Overlapped_Prophages_Isolates_Phaster.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Tool Overlap Script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
